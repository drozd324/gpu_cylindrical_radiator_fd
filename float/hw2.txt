

    ==================================================
    ==================================================
    ==================================================
    MAP55616-02 - Cylindrical Radiator Finite Differences model

    The goal of this assignment is to write a model for propagation of heat inside a cylindrical radiator. You must submit proof of progress in the
	form of a git repository with clear for both the source code and the report, so make sure that you label the commits at the most significant points
	of the development (cpu code working, transfers to the device, basic gpu implementation, each advanced gpu implementation, transfers back to the host,
	and so on.). If you do not include proof of progress, the marks for the parts involved in the source code and report will be halved!

    ==============================================================================================================
    Task 1 - calculation in the cpu

    Write C or C++ code in .h/.c or .hpp/.cpp files that allocates two floating (not double) point matrices of size n x m (both with a default value
	of 32 but that can be specified by passing the command line arguments -n and -m, respectively). The default number of iterations will be 10, but
	add a command line argument so it have to be specified with a -p number.

    The boundary conditions will be:

        in column 0, matrix[i][0] = 0.98*(float)((i+1)*(i+1))/(float)(n*n) (so the values range between 0.98/(float)(n*n) and 0.98)

    Those values will remain constant and thus columns 0 does not need to be calculated on each time step. Initial conditions in [ui][uj] will be the
	value in [ui][0] multiplied by  ( (m-uj)*(m-uj)  / (m*m)) in any other position of the matrices that isn't in column 0.

    Propagation of heat happens only in rows (so there is no vertical propagation) and is directional (in the sense that water in the radiator flows mostly 
	towards "the right"), by applying the following weights:

    (*nextMatrix)[ui][uj]= ( (1.60*(*previousMatrix)[ui][uj-2])+(1.55*(*previousMatrix)[ui][uj-1])+ (*previousMatrix)[ui][uj ]+ (0.60*(*previousMatrix)[ui][uj+1])+(0.25*(*previousMatrix)[ui][uj+2]) );
	(*nextMatrix)[ui][uj]/=(float)(5.0);

    The radiator is horizontally cylindrical (and a bit of heat propagates leftwise as well) and each row (pipe) is a cycle, so,
	for example, to compute the positions:

        new [ui][m-2], you will need the values of old [ui][m-4],[ui][m-3],[ui][m-2],[ui][m-1] and [ui][0]
        new [ui][m-1], you will need the values of old [ui][m-3],[ui][m-2],[ui][m-1],[ui][0] and [ui][1]
        and so on.


    Add an command line option (say, "-a"), so that, after the designated number of heat propagation time steps has been concluded, the average temperature for each row of the radiator gets calculated (this represents the thermostat that would be used to stop heating once it has reached a certain level).
    Task 2 - parallel implementation

    From the code in the host, add cuda code in .h and .cu files that implements the same model in the gpu. To make things easier, you can make the following assumptions:

    * Check that the block size (number of threads per block) can divide the total size of the matrix and stop execution if it does not.

    * Add a "-c" flag to your code so the cpu part of the calculation can be skipped (as this is useful for debugging the gpu code and finding the ideal block size - you do not need to recalculate the cpu part every time that run the gpu one).

    * Remember that the final n and m sizes are expected to be a multiple of your block size (rectangular cases, in which m != n, must still work, though) - it is recommended to start with smaller problem and block sizes (say, 5), for easier debugging.

    * Feel free to use atomics, as well as shared, texture or surface memory, or any other CUDA feature (but not other libraries other than CUDA) to speed up the calculation. Feel free to check and reuse the provided source code (for example, you can use cudaEvents, atomic, sharedMemory, etc).

    * You can organize the grid in whatever way you want (1d, 2d, etc).

    * Implement the row average calculation in a different kernel, so timing can be calculated independently (and that way you get a average-reduce operation that you can use from now on).

    You will need to copy back the results to the RAM; compare them (both the matrices and the averages) with the values obtained in the CPU and report any mismatches larger than 1.E-4 and the maximum difference found between them. Add code to track the amount of time (use cuda events for the gpu parts) that each one of the steps takes (compute on the cpu, allocation on the gpu, transfer to the gpu, compute on the gpu, calculation of the averages, transfer back to the ram) takes, and add a command line argument (-t) to display both the CPU and GPU timings and speedups next to each other.
    Task 3 - performance improvement

    Test the code for different sizes, use n=15360,m=15360 and p=1000 as a reference. Try as well different numbers of threads per block, so use different numbers in each one of the x and y directions if you are using a 2d grid. Calculate the speedups (CPU vs GPU) and precisions compared to the CPU versions.

    Comment on how the new reduce that you have implemented to calculate the average temperature per row performed compared to the reduce operation that you implemented for the first assignment.

    Note: In this assignment, for decent CPU code, you can expect reasonable but not particularly large speedups (In the reference code, the single precision case takes ~5 seconds in the 2080Super, for example - but this is in very optimized code, so getting less than ten seconds (not including transfers to and from the GPU) on the GPU is already pretty decent)- however, the lower that the cuda execution times are, the more marks that the assignment will receive.
    Task 4 - double precision version

    Port the code to a double precision format and compare the times, speedups and mismatches, if any.

    ==============================================================================================================

    Submit a tar ball with your source code files (including a working Makefile for cuda01), speedup graphs and a writeup of what you did and any observations you have made on the behaviour and performance of your code, as well as problems that you came across while writing the assignment. You do not need to include your source code in the report as it will be checked independently. Focus the report on why you chose a particular method to optimize the code and how it worked (or didn't).


    Note: Do not forget to include the proof of progress!

    Note: Do not forget to set up your PATH and LD_LIBRARY_PATH variables in your .bashrc, otherwise nvcc won't work!

    Note: Make sure that back propagation works! (so positions [ui][m-1] and [ui][m-2] get heat from [ui][0] and [ui][1]) 

    Note: Marks will be deducted for tarbombing. http://en.wikipedia.org/wiki/Tar_%28computing%29#Tarbomb

    Note: Extra marks will be given for separating the C/C++ and cuda code. You can find examples on how to do that on the "makefileCpp" and "makefileExternC" sample code.

    Note: Remember that the code must work for non-square systems too, even when, for this assignment, we are using square ones for benchmarking. You can run use compute-sanitizer to test that, as in: /usr/local/cuda-12.8/bin/compute-sanitizer ./my_exec

    Note: When you are benchmarking the performance of your code, you can check the current load on cuda01 with the nvidia-smi command.

    Note: All the elements of each row has to be calculated! Don't skip positions just because their values might not change after the system reaches a stable state.

    Deadline: Friday the 18th of April of 2025, at 17:00

    ==============================================================================================================


